{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import os, sys, re, gc, pickle, operator, shutil, copy, random\n",
    "import time, datetime\n",
    "\n",
    "from math import floor, ceil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GroupKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, Sampler\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: ImportWarning: can't resolve package from __spec__ or __package__, falling back on __name__ and __path__\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from pytorch_pretrained_bert import convert_tf_checkpoint_to_pytorch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertForSequenceClassification, BertAdam, BertConfig\n",
    "from pytorch_pretrained_bert.modeling import BertModel, BertPreTrainedModel\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/kaggle/input/google-quest-challenge/\"\n",
    "BERT_MODEL_PATH = '/kaggle/input/bert-pretrained-models/uncased_l-12_h-768_a-12/uncased_L-12_H-768_A-12/'\n",
    "MODEL_PATH_1 = '../input/gq-bert-2pool-alltrunc/'\n",
    "MODEL_PATH_2 = '../input/gq-bert-2pool-exp/'\n",
    "MODEL_PATH_3 = '../input/gq-bert-2catpool/'\n",
    "MODEL_PATH_4 = '../input/gq-bert-2pool/'\n",
    "\n",
    "SEED = 2019\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seed for randomness in pytorch\n",
    "def seed_everything(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions of data preprocessing and pytorch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks to https://www.kaggle.com/akensert/bert-base-tf2-0-minimalistic\n",
    "def trim_and_tokenize(title, question, answer, max_sequence_length, tokenizer,\n",
    "                      trunc_mode='head', t_max_len=18, q_max_len=245, a_max_len=244):\n",
    "    \n",
    "    assert trunc_mode in {\"head\", \"tail\", \"mix\"}\n",
    "    need_trunc = False\n",
    "\n",
    "    tq_sep = tokenizer.tokenize(\"Details:\")\n",
    "    t = tokenizer.tokenize(title)\n",
    "    q = tokenizer.tokenize(question)\n",
    "    a = tokenizer.tokenize(answer)\n",
    "    \n",
    "    t_len = len(t)\n",
    "    q_len = len(q)\n",
    "    a_len = len(a)\n",
    "\n",
    "    if (t_len+q_len+a_len+5) > max_sequence_length:\n",
    "        need_trunc = True\n",
    "        \n",
    "        if t_max_len > t_len:\n",
    "            t_new_len = t_len\n",
    "            a_max_len = a_max_len + floor((t_max_len - t_len)/2)\n",
    "            q_max_len = q_max_len + ceil((t_max_len - t_len)/2)\n",
    "        else:\n",
    "            t_new_len = t_max_len\n",
    "      \n",
    "        if a_max_len > a_len:\n",
    "            a_new_len = a_len \n",
    "            q_new_len = q_max_len + (a_max_len - a_len)\n",
    "        elif q_max_len > q_len:\n",
    "            a_new_len = a_max_len + (q_max_len - q_len)\n",
    "            q_new_len = q_len\n",
    "        else:\n",
    "            a_new_len = a_max_len\n",
    "            q_new_len = q_max_len\n",
    "            \n",
    "        if t_new_len+a_new_len+q_new_len+5 != max_sequence_length:\n",
    "            raise ValueError(\"New sequence length should be %d, but is %d\" \n",
    "                             % (max_sequence_length, (t_new_len+a_new_len+q_new_len+5)))\n",
    "        \n",
    "        if trunc_mode == \"head\":\n",
    "            t = t[:t_new_len]\n",
    "            q = q[:q_new_len]\n",
    "            a = a[:a_new_len]\n",
    "        if trunc_mode == \"tail\":\n",
    "            t = t[-t_new_len:]\n",
    "            q = q[-q_new_len:]\n",
    "            a = a[-a_new_len:]\n",
    "        if trunc_mode == \"mix\":\n",
    "            def trunc_seq(seq, seq_max_len, trunc_ratio=0.6):\n",
    "                maj_len = int(seq_max_len * trunc_ratio)\n",
    "                return seq[:maj_len] + seq[-(seq_max_len-maj_len):]\n",
    "            t = trunc_seq(t, t_new_len)\n",
    "            q = trunc_seq(q, q_new_len)\n",
    "            a = trunc_seq(a, a_new_len)\n",
    "    \n",
    "    return t, tq_sep, q, a, need_trunc\n",
    "\n",
    "\n",
    "# Tokenizing the lines to BERT token\n",
    "def convert_lines(df, columns, max_sequence_length, tokenizer, trunc_mode='head', misc_trunc=False, target=None):\n",
    "    all_tokens = []\n",
    "    segment_ids = []   # representing segmentation of sentence A and B\n",
    "    if target is not None:\n",
    "        labels = []\n",
    "    \n",
    "    for ind, (_, instance) in enumerate(df[columns].iterrows()):\n",
    "        \n",
    "        title, question, answer = instance.question_title, instance.question_body, instance.answer\n",
    "        t, tq_sep, q, a, need_trunc = trim_and_tokenize(title, question, answer,\n",
    "                                                        max_sequence_length, tokenizer, trunc_mode=trunc_mode)\n",
    "        tokens = [\"[CLS]\"] + t + tq_sep + q + [\"[SEP]\"] + a + [\"[SEP]\"]\n",
    "        all_tokens.append(tokenizer.convert_tokens_to_ids(tokens))\n",
    "        segment_ids.append([0]*(len(t)+len(tq_sep)+len(q)+2) + [1]*(len(a)+1))\n",
    "        if target is not None:\n",
    "            labels.append(target[ind])\n",
    "        \n",
    "        if need_trunc and misc_trunc:\n",
    "            t, tq_sep, q, a, _ = trim_and_tokenize(title, question, answer,\n",
    "                                                   max_sequence_length, tokenizer, trunc_mode='tail')\n",
    "            tokens = [\"[CLS]\"] + t + tq_sep + q + [\"[SEP]\"] + a + [\"[SEP]\"]\n",
    "            all_tokens.append(tokenizer.convert_tokens_to_ids(tokens))\n",
    "            segment_ids.append([0]*(len(t)+len(tq_sep)+len(q)+2) + [1]*(len(a)+1))\n",
    "\n",
    "            t, tq_sep, q, a, _ = trim_and_tokenize(title, question, answer,\n",
    "                                                   max_sequence_length, tokenizer, trunc_mode='mix')\n",
    "            tokens = [\"[CLS]\"] + t + tq_sep + q + [\"[SEP]\"] + a + [\"[SEP]\"]\n",
    "            all_tokens.append(tokenizer.convert_tokens_to_ids(tokens))\n",
    "            segment_ids.append([0]*(len(t)+len(tq_sep)+len(q)+2) + [1]*(len(a)+1))\n",
    "\n",
    "            if target is not None:\n",
    "                labels.extend([target[ind], target[ind]])\n",
    "    \n",
    "    if target is not None:\n",
    "        return np.array(all_tokens), np.array(segment_ids), np.array(labels)\n",
    "    return np.array(all_tokens), np.array(segment_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset and dataloader\n",
    "\n",
    "class QuestQAs(Dataset):\n",
    "\n",
    "    def __init__(self, tokenized_comments, segment_ids, targets=None, split=None, maxlen=256):\n",
    "        self.comments = tokenized_comments\n",
    "        self.segment_ids = segment_ids\n",
    "        self.targets = targets\n",
    "        self.split = split\n",
    "        assert self.split in {'train', 'valid', 'test'}\n",
    "        self.maxlen = maxlen\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        comment = self.comments[index]\n",
    "        segment_id = self.segment_ids[index]\n",
    "        if self.targets is not None:\n",
    "            target = self.targets[index]\n",
    "            return comment, segment_id, torch.FloatTensor(target)\n",
    "        else:\n",
    "            return comment, segment_id\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.comments)\n",
    "\n",
    "    def get_lens(self):\n",
    "        lengths = np.fromiter(\n",
    "            ((min(self.maxlen, len(seq))) for seq in self.comments),\n",
    "            dtype=np.int32)\n",
    "        return lengths\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"\n",
    "        Collate function for sequence bucketing\n",
    "        Note: this need not be defined in this Class, can be standalone.\n",
    "\n",
    "        :param batch: an iterable of N sets from __getitem__()\n",
    "        :return: a tensor of comments, and targets\n",
    "        \"\"\"\n",
    "\n",
    "        if self.split in ('train', 'valid'):\n",
    "            comments, segment_ids, targets = zip(*batch)\n",
    "        else:\n",
    "            comments, segment_ids = zip(*batch)\n",
    "\n",
    "        lengths = [len(c) for c in comments]\n",
    "        maxlen = max(lengths)\n",
    "        padded_comments, padded_seg_ids = [], []\n",
    "        for i, (c, s) in enumerate(zip(comments, segment_ids)):\n",
    "            padded_comments.append(c+[0]*(maxlen - lengths[i]))\n",
    "            padded_seg_ids.append(s +[0]*(maxlen - lengths[i]))\n",
    "\n",
    "        if self.split in ('train', 'valid'):\n",
    "            return torch.LongTensor(padded_comments), torch.LongTensor(padded_seg_ids), torch.stack(targets)\n",
    "        else:\n",
    "            return torch.LongTensor(padded_comments), torch.LongTensor(padded_seg_ids)\n",
    "\n",
    "\n",
    "class BucketSampler(Sampler):\n",
    "\n",
    "    def __init__(self, data_source, sort_lens, bucket_size=None, batch_size=1024, shuffle_data=True):\n",
    "        super().__init__(data_source)\n",
    "        self.shuffle = shuffle_data\n",
    "        self.batch_size = batch_size\n",
    "        self.sort_lens = sort_lens\n",
    "        self.bucket_size = bucket_size if bucket_size is not None else len(sort_lens)\n",
    "        self.weights = None\n",
    "\n",
    "        if not shuffle_data:\n",
    "            self.index = self.prepare_buckets()\n",
    "        else:\n",
    "            self.index = None\n",
    "\n",
    "    def set_weights(self, weights):\n",
    "        assert weights >= 0\n",
    "        total = np.sum(weights)\n",
    "        if total != 1:\n",
    "            weights = weights / total\n",
    "        self.weights = weights\n",
    "\n",
    "    def __iter__(self):\n",
    "        indices = None\n",
    "        if self.weights is not None:\n",
    "            total = len(self.sort_lens)\n",
    "            indices = np.random.choice(total, (total,), p=self.weights)\n",
    "        if self.shuffle:\n",
    "            self.index = self.prepare_buckets(indices)\n",
    "        return iter(self.index)\n",
    "\n",
    "    def get_reverse_indexes(self):\n",
    "        indexes = np.zeros((len(self.index),), dtype=np.int32)\n",
    "        for i, j in enumerate(self.index):\n",
    "            indexes[j] = i\n",
    "        return indexes\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sort_lens)\n",
    "\n",
    "    def prepare_buckets(self, indices=None):\n",
    "        lengths = - self.sort_lens\n",
    "        assert self.bucket_size % self.batch_size == 0 or self.bucket_size == len(lengths)\n",
    "\n",
    "        if indices is None:\n",
    "            if self.shuffle:\n",
    "                indices = shuffle(np.arange(len(lengths), dtype=np.int32))\n",
    "                lengths = lengths[indices]\n",
    "            else:\n",
    "                indices = np.arange(len(lengths), dtype=np.int32)\n",
    "\n",
    "        #  bucket iterator\n",
    "        def divide_chunks(l, n):\n",
    "            if n == len(l):\n",
    "                yield np.arange(len(l), dtype=np.int32), l\n",
    "            else:\n",
    "                # looping till length l\n",
    "                for i in range(0, len(l), n):\n",
    "                    data = l[i:i + n]\n",
    "                    yield np.arange(i, i + len(data), dtype=np.int32), data\n",
    "\n",
    "        new_indices = []\n",
    "        extra_batch_idx = None\n",
    "        for chunk_index, chunk in divide_chunks(lengths, self.bucket_size):\n",
    "            # sort indices in bucket by descending order of length\n",
    "            indices_sorted = chunk_index[np.argsort(chunk)]\n",
    "\n",
    "            batch_idxes = []\n",
    "            for _, batch_idx in divide_chunks(indices_sorted, self.batch_size):\n",
    "                if len(batch_idx) == self.batch_size:\n",
    "                    batch_idxes.append(batch_idx.tolist())\n",
    "                else:\n",
    "                    assert extra_batch_idx is None\n",
    "                    assert batch_idx is not None\n",
    "                    extra_batch_idx = batch_idx.tolist()\n",
    "\n",
    "            # shuffling batches within buckets\n",
    "            if self.shuffle:\n",
    "                batch_idxes = shuffle(batch_idxes)\n",
    "            for batch_idx in batch_idxes:\n",
    "                new_indices.extend(batch_idx)\n",
    "\n",
    "        if extra_batch_idx is not None:\n",
    "            new_indices.extend(extra_batch_idx)\n",
    "\n",
    "        if not self.shuffle:\n",
    "            self.original_indices = np.argsort(indices_sorted).tolist()\n",
    "        return indices[new_indices]\n",
    "\n",
    "\n",
    "def prepare_loader(x, seg_ids, y=None, batch_size=None, split=None):\n",
    "    assert split in {'train', 'valid', 'test'}\n",
    "    dataset = QuestQAs(x, seg_ids, y, split, MAX_SEQUENCE_LENGTH)\n",
    "    if split == 'train':\n",
    "        sampler = BucketSampler(dataset, dataset.get_lens(),\n",
    "                                bucket_size=batch_size*20, batch_size=batch_size)\n",
    "        return DataLoader(dataset, batch_size=batch_size, sampler=sampler,\n",
    "                          collate_fn=dataset.collate_fn)\n",
    "    else:\n",
    "        sampler = BucketSampler(dataset, dataset.get_lens(),\n",
    "                                batch_size=batch_size, shuffle_data=False)\n",
    "        return DataLoader(dataset, batch_size=batch_size, sampler=sampler,\n",
    "                          collate_fn=dataset.collate_fn), sampler.original_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertLastTwoClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config, num_labels):\n",
    "        super(BertLastTwoClassification, self).__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(config.hidden_size*4, num_labels)\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None):\n",
    "        encoded_layers, _ = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=True)\n",
    "        seq_op1 = encoded_layers[-1]\n",
    "        seq_op2 = encoded_layers[-2]\n",
    "        avg_pool1 = torch.mean(seq_op1, 1)\n",
    "        max_pool1, _ = torch.max(seq_op1, 1)\n",
    "        avg_pool2 = torch.mean(seq_op2, 1)\n",
    "        max_pool2, _ = torch.max(seq_op2, 1)\n",
    "        pooled_output = torch.cat((avg_pool1, max_pool1, avg_pool2, max_pool2), 1)\n",
    "        return self.classifier(self.dropout(pooled_output))\n",
    "\n",
    "\n",
    "class BertCatLastTwoClassification(BertPreTrainedModel):\n",
    "    def __init__(self, config, num_labels):\n",
    "        super(BertCatLastTwoClassification, self).__init__(config)\n",
    "        self.num_labels = num_labels\n",
    "        self.bert = BertModel(config)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(config.hidden_size*4, num_labels)\n",
    "        self.apply(self.init_bert_weights)\n",
    "\n",
    "    def forward(self, input_ids, token_type_ids=None, attention_mask=None):\n",
    "        encoded_layers, _ = self.bert(input_ids, token_type_ids, attention_mask, output_all_encoded_layers=True)\n",
    "        seq_op1 = encoded_layers[-1]   # (N, T, D)\n",
    "        seq_op2 = encoded_layers[-2]   # (N, T, D)\n",
    "        seq_cat = torch.cat((seq_op1, seq_op2), -1)   # (N, T, 2D)\n",
    "        avg_pool = torch.mean(seq_cat, 1)   # (N, 2D)\n",
    "        max_pool, _ = torch.max(seq_cat, 1)   # (N, 2D)\n",
    "        pooled_output = torch.cat((avg_pool, max_pool), 1)   # (N, 4D)\n",
    "        return self.classifier(self.dropout(pooled_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rho(labels, preds):\n",
    "    rhos = []\n",
    "    for col_label, col_pred in zip(labels.T, preds.T):\n",
    "        rhos.append(\n",
    "            spearmanr(col_label, col_pred + np.random.normal(0, 1e-7, col_pred.shape[0])).correlation)\n",
    "    return np.mean(rhos)\n",
    "\n",
    "\n",
    "def eval_rho(labels, preds, columns):\n",
    "    return {col: spearmanr(labels[:,i], preds[:,i] + \\\n",
    "                np.random.normal(0, 1e-7, len(preds))).correlation  for i, col in enumerate(columns)}\n",
    "\n",
    "\n",
    "def validate(val_loader, model, val_original_indices, post_indices=None):\n",
    "    model.eval()\n",
    "    targets, scores = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, seg_ids, y in val_loader:\n",
    "            x, y = x.to(device=device, dtype=torch.long), y.to(device=device, dtype=torch.float)\n",
    "            seg_ids = seg_ids.to(device=device, dtype=torch.long)\n",
    "            score = torch.sigmoid(model(x, token_type_ids=seg_ids, attention_mask=(x>0)))\n",
    "            targets.append(y.cpu().numpy())\n",
    "            scores.append(score.cpu().numpy())\n",
    "\n",
    "    targets = np.concatenate(targets)[val_original_indices]\n",
    "    scores = np.concatenate(scores)[val_original_indices]\n",
    "\n",
    "    if post_indices is not None:\n",
    "        scores[:, 19] = 0\n",
    "        scores[post_indices, 19] += 0.5\n",
    "\n",
    "    val_rho = compute_rho(targets, scores)\n",
    "    print('{\"metric\": \"Val. Rho\", \"value\": %.4f}' % (val_rho, ))\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def eval_model(model, test_loader):\n",
    "    model.eval()\n",
    "    test_scores = []\n",
    "    with torch.no_grad():\n",
    "        for x, seg_ids in test_loader:\n",
    "            x = x.to(device=device, dtype=torch.long)\n",
    "            seg_ids = seg_ids.to(device=device, dtype=torch.long)\n",
    "            score = torch.sigmoid(model(x, token_type_ids=seg_ids, attention_mask=(x>0)))\n",
    "            test_scores.append(score.cpu().numpy())\n",
    "    return np.concatenate(test_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load/preprocess the data, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_val_split(train_df):\n",
    "#     kf = GroupKFold(n_splits=5)\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=SEED)\n",
    "#     cv_indices = [(tr_idx, val_idx) for tr_idx, val_idx in kf.split(train_df.question_body, groups=train_df.question_body)]\n",
    "    cv_indices = [(tr_idx, val_idx) for tr_idx, val_idx in kf.split(train_df)]\n",
    "    return cv_indices\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    train_df = pd.read_csv(DATA_DIR+'train.csv')\n",
    "    output_cols = list(train_df.columns[11:])\n",
    "    input_cols = list(train_df.columns[[1,2,5]])\n",
    "    \n",
    "    train_tars = train_df[output_cols].values.astype('float32')\n",
    "    \n",
    "    return train_tars, train_df, input_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(BERT_MODEL_PATH, do_lower_case=True)\n",
    "train_tars, train_df, input_cols = load_data()\n",
    "cv_indices = train_val_split(train_df)\n",
    "\n",
    "bert_config = BertConfig(BERT_MODEL_PATH + 'bert_config.json')\n",
    "model = BertLastTwoClassification(bert_config, num_labels=30)\n",
    "model = model.to(device)\n",
    "model2 = BertCatLastTwoClassification(bert_config, num_labels=30)\n",
    "model2 = model2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.4049}\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.4060}\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.4075}\n",
      "\n",
      "Fold 2 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3928}\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3926}\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3941}\n",
      "\n",
      "Fold 3 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.4029}\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.4022}\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.4038}\n",
      "\n",
      "Fold 4 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3844}\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3835}\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3871}\n",
      "\n",
      "Fold 5 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3959}\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3971}\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3977}\n",
      "\n",
      "1318.291968M\n",
      "1482.686464M\n",
      "\n",
      "CPU times: user 5min 33s, sys: 1min 24s, total: 6min 57s\n",
      "Wall time: 7min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "oof_targets = []\n",
    "oof_preds_head = []\n",
    "oof_preds_tail = []\n",
    "oof_preds_mix = []\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(cv_indices):\n",
    "    print(f'Fold {i+1} validating:')\n",
    "    \n",
    "    model_ckpts = torch.load(MODEL_PATH_1+f'fld_{i}_quest_bert_models.pt')['model']\n",
    "    model.load_state_dict(model_ckpts[list(model_ckpts.keys())[-1]])\n",
    "    y_val = train_tars[val_idx]\n",
    "    oof_targets.append(y_val)\n",
    "    print()\n",
    "    \n",
    "    x_val, seg_val = convert_lines(train_df.iloc[val_idx], input_cols,\n",
    "                                   MAX_SEQUENCE_LENGTH, tokenizer)\n",
    "    val_loader, val_original_indices = prepare_loader(x_val, seg_val, y_val, 16, split='valid')\n",
    "    oof_preds_head.append(validate(val_loader, model, val_original_indices))\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    x_val, seg_val = convert_lines(train_df.iloc[val_idx], input_cols,\n",
    "                                   MAX_SEQUENCE_LENGTH, tokenizer,\n",
    "                                   trunc_mode='tail')\n",
    "    val_loader, val_original_indices = prepare_loader(x_val, seg_val, y_val, 16, split='valid')\n",
    "    oof_preds_tail.append(validate(val_loader, model, val_original_indices))\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    x_val, seg_val = convert_lines(train_df.iloc[val_idx], input_cols,\n",
    "                                   MAX_SEQUENCE_LENGTH, tokenizer,\n",
    "                                   trunc_mode='mix')\n",
    "    val_loader, val_original_indices = prepare_loader(x_val, seg_val, y_val, 16, split='valid')\n",
    "    oof_preds_mix.append(validate(val_loader, model, val_original_indices))\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print()\n",
    "\n",
    "oof_targets = np.concatenate(oof_targets)\n",
    "oof_preds_head = np.concatenate(oof_preds_head)\n",
    "oof_preds_tail = np.concatenate(oof_preds_tail)\n",
    "oof_preds_mix = np.concatenate(oof_preds_mix)\n",
    "oof_preds = np.mean([oof_preds_head, oof_preds_tail, oof_preds_mix], 0)\n",
    "\n",
    "print(str(torch.cuda.memory_allocated(device)/1e6 ) + 'M')\n",
    "print(str(torch.cuda.memory_cached(device)/1e6 ) + 'M')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF rho of head trunc: 0.39220573170012807\n",
      "OOF rho of tail trunc: 0.39238062891537673\n",
      "OOF rho of mix trunc: 0.3940194586152391\n",
      "OOF rho of all truncs: 0.39502341805226227\n",
      "OOF rho of weighted truncs: 0.3949563597837244\n"
     ]
    }
   ],
   "source": [
    "print(f'OOF rho of head trunc: {compute_rho(oof_targets, oof_preds_head)}')\n",
    "print(f'OOF rho of tail trunc: {compute_rho(oof_targets, oof_preds_tail)}')\n",
    "print(f'OOF rho of mix trunc: {compute_rho(oof_targets, oof_preds_mix)}')\n",
    "print(f'OOF rho of all truncs: {compute_rho(oof_targets, oof_preds)}')\n",
    "print(f'OOF rho of weighted truncs: {compute_rho(oof_targets, (3*oof_preds_head + 2*oof_preds_tail + 2*oof_preds_mix) / 7)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Post processing\n",
    "\n",
    "# col_ind = np.where(train_df.columns[11:] == 'question_type_spelling')[0][0]\n",
    "# post_idx = np.where((train_df.category == \"CULTURE\") & \\\n",
    "#                     ((train_df.host == \"english.stackexchange.com\") | (train_df.host == \"ell.stackexchange.com\")))[0]\n",
    "\n",
    "# pred_post = np.zeros(len(train_df))\n",
    "# pred_post[post_idx] += 1\n",
    "\n",
    "# oof_preds_head[:, col_ind] = pred_post\n",
    "# oof_preds_tail[:, col_ind] = pred_post\n",
    "# oof_preds_mix[:, col_ind] = pred_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('After post-processing')\n",
    "# print(f'OOF rho of head trunc: {compute_rho(oof_targets, oof_preds_head)}')\n",
    "# print(f'OOF rho of tail trunc: {compute_rho(oof_targets, oof_preds_tail)}')\n",
    "# print(f'OOF rho of mix trunc: {compute_rho(oof_targets, oof_preds_mix)}')\n",
    "# print(f'OOF rho of all truncs: {compute_rho(oof_targets, np.mean([oof_preds_head, oof_preds_tail, oof_preds_mix], 0))}')\n",
    "# print(f'OOF rho of weighted truncs: {compute_rho(oof_targets, (3*oof_preds_head + 2*oof_preds_tail + 2*oof_preds_mix) / 7)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.4007}\n",
      "\n",
      "Fold 2 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3858}\n",
      "\n",
      "Fold 3 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3944}\n",
      "\n",
      "Fold 4 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3829}\n",
      "\n",
      "Fold 5 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3925}\n",
      "\n",
      "1318.291968M\n",
      "1566.572544M\n",
      "\n",
      "OOF rho of all truncs: 0.3887391530691789\n",
      "CPU times: user 1min 51s, sys: 28.9 s, total: 2min 20s\n",
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "oof_2_preds = []\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(cv_indices):\n",
    "    print(f'Fold {i+1} validating:')\n",
    "    \n",
    "    model_ckpts = torch.load(MODEL_PATH_2+f'fld_{i}_quest_bert_models.pt')['model']\n",
    "    model.load_state_dict(model_ckpts[list(model_ckpts.keys())[-1]])\n",
    "    y_val = train_tars[val_idx]\n",
    "    print()\n",
    "    \n",
    "    x_val, seg_val = convert_lines(train_df.iloc[val_idx], input_cols,\n",
    "                                   MAX_SEQUENCE_LENGTH, tokenizer)\n",
    "    val_loader, val_original_indices = prepare_loader(x_val, seg_val, y_val, 16, split='valid')\n",
    "    oof_2_preds.append(validate(val_loader, model, val_original_indices))\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print()\n",
    "\n",
    "oof_2_preds = np.concatenate(oof_2_preds)\n",
    "    \n",
    "print(str(torch.cuda.memory_allocated(device)/1e6 ) + 'M')\n",
    "print(str(torch.cuda.memory_cached(device)/1e6 ) + 'M')\n",
    "print()\n",
    "\n",
    "print(f'OOF rho of all truncs: {compute_rho(oof_targets, oof_2_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.4015}\n",
      "\n",
      "Fold 2 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3923}\n",
      "\n",
      "Fold 3 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3981}\n",
      "\n",
      "Fold 4 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3835}\n",
      "\n",
      "Fold 5 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3921}\n",
      "\n",
      "1318.291968M\n",
      "1587.544064M\n",
      "\n",
      "OOF rho of all truncs: 0.3913146618495562\n",
      "CPU times: user 1min 53s, sys: 29 s, total: 2min 22s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "oof_3_preds = []\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(cv_indices):\n",
    "    print(f'Fold {i+1} validating:')\n",
    "    \n",
    "    model_ckpts = torch.load(MODEL_PATH_3+f'fld_{i}_quest_bert_models.pt')['model']\n",
    "    model2.load_state_dict(model_ckpts[list(model_ckpts.keys())[-1]])\n",
    "    y_val = train_tars[val_idx]\n",
    "    print()\n",
    "    \n",
    "    x_val, seg_val = convert_lines(train_df.iloc[val_idx], input_cols,\n",
    "                                   MAX_SEQUENCE_LENGTH, tokenizer)\n",
    "    val_loader, val_original_indices = prepare_loader(x_val, seg_val, y_val, 16, split='valid')\n",
    "    oof_3_preds.append(validate(val_loader, model2, val_original_indices))\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print()\n",
    "\n",
    "oof_3_preds = np.concatenate(oof_3_preds)\n",
    "    \n",
    "print(str(torch.cuda.memory_allocated(device)/1e6 ) + 'M')\n",
    "print(str(torch.cuda.memory_cached(device)/1e6 ) + 'M')\n",
    "print()\n",
    "\n",
    "print(f'OOF rho of all truncs: {compute_rho(oof_targets, oof_3_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.4033}\n",
      "\n",
      "Fold 2 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3859}\n",
      "\n",
      "Fold 3 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3909}\n",
      "\n",
      "Fold 4 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3843}\n",
      "\n",
      "Fold 5 validating:\n",
      "\n",
      "{\"metric\": \"Val. Rho\", \"value\": 0.3944}\n",
      "\n",
      "1318.291968M\n",
      "1692.401664M\n",
      "\n",
      "OOF rho of all truncs: 0.3892913935729739\n",
      "CPU times: user 1min 53s, sys: 29 s, total: 2min 22s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "oof_4_preds = []\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(cv_indices):\n",
    "    print(f'Fold {i+1} validating:')\n",
    "    \n",
    "    model_ckpts = torch.load(MODEL_PATH_4+f'fld_{i}_quest_bert_models.pt')['model']\n",
    "    model.load_state_dict(model_ckpts[list(model_ckpts.keys())[-1]])\n",
    "    y_val = train_tars[val_idx]\n",
    "    print()\n",
    "    \n",
    "    x_val, seg_val = convert_lines(train_df.iloc[val_idx], input_cols,\n",
    "                                   MAX_SEQUENCE_LENGTH, tokenizer,\n",
    "                                   trunc_mode='tail')\n",
    "    val_loader, val_original_indices = prepare_loader(x_val, seg_val, y_val, 16, split='valid')\n",
    "    oof_4_preds.append(validate(val_loader, model, val_original_indices))\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print()\n",
    "\n",
    "oof_4_preds = np.concatenate(oof_4_preds)\n",
    "    \n",
    "print(str(torch.cuda.memory_allocated(device)/1e6 ) + 'M')\n",
    "print(str(torch.cuda.memory_cached(device)/1e6 ) + 'M')\n",
    "print()\n",
    "\n",
    "print(f'OOF rho of all truncs: {compute_rho(oof_targets, oof_4_preds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_processing_and_eval(y_true, y_pred):\n",
    "    \n",
    "    y = copy.deepcopy(y_pred)\n",
    "    list_of_max_voters = []\n",
    "    # list_of_max_voters[i] will be\n",
    "    # how many voters did label the data (instead of 90 for all the columns)\n",
    "    # from https://www.kaggle.com/c/google-quest-challenge/discussion/129831\n",
    "    \n",
    "    for i in (range(y_pred.shape[1])):\n",
    "        \n",
    "        best_score = 0\n",
    "        best_max_voters = 1\n",
    "        history_score = []\n",
    "        \n",
    "        for max_voters in range(1,200):\n",
    "            y[:,i] = (y_pred[:,i] // (1/max_voters)) * (1/max_voters)\n",
    "            score = spearmanr(y_true[:, i], y[:, i]).correlation\n",
    "            history_score.append(score)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_max_voters = max_voters\n",
    "        \n",
    "        list_of_max_voters.append(best_max_voters)\n",
    "        y[:,i] = (y_pred[:,i] // (1/best_max_voters)) * (1/best_max_voters)\n",
    "    \n",
    "    return compute_rho(y_true, y), list_of_max_voters\n",
    "#     return np.mean([spearmanr(y_true[:, ind], y[:, ind]).correlation for ind in range(y.shape[1])]), list_of_max_voters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF rho before post-processing: 0.4064911201282894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/numpy/lib/function_base.py:2530: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/opt/conda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/opt/conda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:877: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "/opt/conda/lib/python3.6/site-packages/scipy/stats/_distn_infrastructure.py:1831: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF rho after post-processing: 0.37910860143401703\n",
      "[142, 30, 6, 33, 13, 4, 86, 23, 7, 142, 15, 9, 6, 9, 8, 7, 5, 50, 36, 149, 52, 24, 49, 81, 88, 64, 17, 54, 50, 127]\n"
     ]
    }
   ],
   "source": [
    "# ensemble models\n",
    "oof_preds = oof_preds*0.3 + oof_2_preds*0.25 + oof_3_preds*0.25 + oof_4_preds*0.2\n",
    "print(f'OOF rho before post-processing: {compute_rho(oof_targets, oof_preds)}')\n",
    "oof_df = pd.DataFrame(oof_preds, columns=list(train_df.columns[11:]))\n",
    "oof_df.to_csv('oof_cv.csv', index=False)\n",
    "\n",
    "cv_rho, list_of_max_voters = post_processing_and_eval(oof_targets, oof_preds)\n",
    "print(f'OOF rho after post-processing: {cv_rho}')\n",
    "print(list_of_max_voters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF rho after post-processing: 0.3805010308746449\n"
     ]
    }
   ],
   "source": [
    "raters = np.array([18, 18,  6,  6,  6,  6, 18, 18,  6,  6,  6,  6,  6,  6,  6,  6,  6, 6,  6,  3, 18, 18, 18, 18, 18, 90,  6,  6,  6, 18])\n",
    "\n",
    "mins = np.min(oof_preds, axis=0)\n",
    "maxs = np.max(oof_preds, axis=0)\n",
    "oof_post = (oof_preds - mins)/(maxs - mins)\n",
    "\n",
    "oof_post =  np.round(raters * oof_post).astype(np.float) / raters\n",
    "print(f'OOF rho after post-processing: {compute_rho(oof_targets, oof_post)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
